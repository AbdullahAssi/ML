{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TL5y5fY9Jy_x"
   },
   "source": [
    "# Lab 6: Neural networks \n",
    "\n",
    "In this lab we will build dense neural networks on the MNIST dataset.\n",
    "\n",
    "Make sure you read the tutorial for this lab first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and create train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Abdullah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Auto-setup when running on Google Colab\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openml as oml\n",
    "import tensorflow.keras as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdullah\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Abdullah\\AppData\\Local\\Temp\\ipykernel_9508\\3841004139.py:3: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute, dataset_format='array');\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download MNIST data. Takes a while the first time.\n",
    "mnist = oml.datasets.get_dataset(554)\n",
    "X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute, dataset_format='array');\n",
    "X = X.reshape(70000, 28, 28)\n",
    "\n",
    "# Take some random examples\n",
    "from random import randint\n",
    "fig, axes = plt.subplots(1, 5,  figsize=(10, 5))\n",
    "for i in range(5):\n",
    "    n = randint(0,70000)\n",
    "    axes[i].imshow(X[n], cmap=plt.cm.gray_r)\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "    axes[i].set_xlabel(\"{}\".format(y[n]))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JZlvdpyYKx7V"
   },
   "outputs": [],
   "source": [
    "# For MNIST, there exists a predefined stratified train-test split of 60000-10000. We therefore don't shuffle or stratify here.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=60000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ldP-5z1B2vL"
   },
   "source": [
    "## Exercise 1: Preprocessing\n",
    "* Normalize the data: map each feature value from its current representation (an integer between 0 and 255) to a floating-point value between 0 and 1.0. \n",
    "* Store the floating-point values in `x_train_normalized` and `x_test_normalized`.\n",
    "* Map the class label to a on-hot-encoded value. Store in `y_train_encoded` and `y_test_encoded`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3014ezH3C7jT"
   },
   "source": [
    "## Exercise 2: Create a deep neural net model\n",
    "\n",
    "Implement a `create_model` function which defines the topography of the deep neural net, specifying the following:\n",
    "\n",
    "* The number of layers in the deep neural net: Use 2 dense layers for now.\n",
    "* The number of nodes in each layer: these are parameters of your function.\n",
    "* Any regularization layers. Add at least one dropout layer.\n",
    "* The optimizer and learning rate. Make the learning rate a parameter of your function as well.\n",
    "\n",
    "Consider:\n",
    "* What should be the shape of the input layer?\n",
    "* Which activation function you will need for the last layer, since this is a 10-class classification problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create and compile a 'deep' neural net\n",
    "def create_model(layer_1_units=32, layer_2_units=10, learning_rate=0.001, dropout_rate=0.3):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Create a training function\n",
    "Implement a `train_model` function which trains and evaluates a given model.\n",
    "It should do a train-validation split and report the train and validation loss and accuracy, and return the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y, validation_split=0.1, epochs=10, batch_size=None):\n",
    "    \"\"\"\n",
    "    model: the model to train\n",
    "    X, y: the training data and labels\n",
    "    validation_split: the percentage of data set aside for the validation set\n",
    "    epochs: the number of epochs to train for\n",
    "    batch_size: the batch size for minibatch SGD\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-IXYVfvM4gD"
   },
   "source": [
    "## Exercise 4: Evaluate the model\n",
    "\n",
    "Train the model with a learning rate of 0.003, 50 epochs, batch size 4000, and a validation set that is 20% of the total training data.\n",
    "Use default settings otherwise. Plot the learning curve of the loss, validation loss, accuracy, and validation accuracy. Finally, report the performance on the test set.\n",
    "\n",
    "Feel free to use the plotting function below, or implement the callback from the tutorial to see results in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "QF0BFRXTOeR3"
   },
   "outputs": [],
   "source": [
    "# Helper plotting function\n",
    "#\n",
    "# history: the history object returned by the fit function\n",
    "# list_of_metrics: the metrics to plot\n",
    "def plot_curve(history, list_of_metrics):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    for m in list_of_metrics:\n",
    "        x = hist[m]\n",
    "        plt.plot(epochs[1:], x[1:], label=m, lw=2)\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5IKmk7D49_n"
   },
   "source": [
    "## Exercise 5: Optimize the model\n",
    "\n",
    "Try to optimize the model, either manually or with a tuning method. At least optimize the following:\n",
    "* the number of hidden layers \n",
    "* the number of nodes in each layer\n",
    "* the amount of dropout layers and the dropout rate\n",
    "\n",
    "Try to reach at least 96% accuracy against the test set."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Multi-class classification with MNIST.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
